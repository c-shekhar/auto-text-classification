## auto-text-classification
One of the widely used natural language processing task in different business problems is “Text Classification”.  
The goal of text classification is to classify the text documents into one or more defined categories.  
Some examples of text classification are:
 - Understanding audience sentiment from social media,
 - Detection of spam and non-spam emails,
 - Auto tagging of customer queries, and
 - Categorization of news articles into defined topics.

There are list of steps common to every text classification problem like:
1. Dataset Preparation.
2. Feature Engineerin, i.e. Transforming words into meaningful numbers.
3. Model Training.  

There are known algorithms which convert text to numbers which can be then fed to classical machine  
or deep learning models to classify into the desired categories.  
List of the algorithms currently implemented in auto-text-classification to convert  
into meaningful embeddings are:
1. Count-based embeddings
    - Bag Of Words
    - Tf-Idf
2. Learned Embeddings
    - Word2Vec
    - Glove
    - Fasttext
    
